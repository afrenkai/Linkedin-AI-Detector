- gradient ckpt
- early stopping
- param validation (config could just be insane since I took it from jamba)
- cuda oom handling
- tensorboard/wandb viz and logging
- ckpt on val loss
- DL num_workers should adapt to gpus (currently hardcoded to 0)
- amp is being weird, no idea if it's LSP or something else
- docs, typehints
- gradient_clipping_unused in tuning, need to add to comp graph
- roundtrip w/o clean fn
